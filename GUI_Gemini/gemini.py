"""
assistant_ai.py

ğŸ¯ ç›®çš„
    ãƒ»éŸ³å£°å…¥åŠ› â†’ Whisper æ–‡å­—èµ·ã“ã—
    ãƒ»Gemini-2.0-Flash ã§å›ç­”ç”Ÿæˆ
    ãƒ»AIVISpeech ã§éŸ³å£°åˆæˆ â†’ å†ç”Ÿ
    ãƒ»è¦šãˆã¦ï¼å¿˜ã‚Œã¦ï¼ãƒ–ãƒ©ã‚¦ã‚¶è¦ç´„ ãªã©æ—¢å­˜æ©Ÿèƒ½ã¯ãã®ã¾ã¾
    ãƒ»ESC ã§çµ‚äº†ã€F2 ã§éŒ²éŸ³ãƒˆã‚°ãƒ«

ğŸ’¾ ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒª  (ä¾‹: requirements.txt)
    faster-whisper==1.0.1
    google-generativeai==0.5.2
    duckduckgo_search==5.3.0
    feedparser==6.0.11
    sounddevice==0.4.7
    soundfile==0.12.1
    python-dotenv==1.0.1
    Flask==3.0.2
    flask-cors==4.0.0
    beautifulsoup4==4.12.3
"""

# ======= ğŸ“¦ æ¨™æº–ï¼å¤–éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« =======
import os
import time
import json
import re
import tempfile
import threading
from pathlib import Path
from datetime import datetime, timedelta

import numpy as np
import sounddevice as sd
import soundfile as sf
import requests
import keyboard
import feedparser
from bs4 import BeautifulSoup

from dotenv import load_dotenv
from faster_whisper import WhisperModel
import google.generativeai as genai 
import google.genai                   # âœ… Gemini SDK
from duckduckgo_search import DDGS

from flask import Flask, request
from flask_cors import CORS

# ======= ğŸ”§ ç’°å¢ƒå¤‰æ•°ãƒ­ãƒ¼ãƒ‰ =======
load_dotenv()
GENAI_API_KEY = os.getenv("GOOGLE_API_KEY")
OPENWEATHER_API_KEY = os.getenv("OPENWEATHER_API_KEY")

# ======= ğŸ”§ Gemini åˆæœŸåŒ– =======
genai.configure(api_key=GENAI_API_KEY)
GEMINI_MODEL = genai.GenerativeModel("gemini-2.0-flash")  # â† ã“ã“ã§ãƒ¢ãƒ‡ãƒ«æŒ‡å®š

# ======= ğŸ”§ Whisper åˆæœŸåŒ– =======
whisper_model = WhisperModel("medium", device="cuda", compute_type="float16")

# ======= ğŸ§  è¨˜æ†¶ç®¡ç†ãƒ•ã‚¡ã‚¤ãƒ« =======
MEMORY_FILE = Path("gpt_memory.json")
MEMORY_LOCK = threading.Lock()   # åŒæ™‚æ›¸ãè¾¼ã¿å¯¾ç­–

# ======= ğŸšï¸ éŒ²éŸ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ =======
THRESHOLD_START = 0.02   # èªè­˜é–‹å§‹éŸ³é‡
THRESHOLD_STOP  = 0.01   # ç„¡éŸ³åˆ¤å®šéŸ³é‡
SILENCE_DURATION = 1.0   # ç„¡éŸ³ç¶™ç¶šç§’
SAMPLE_RATE = 44_100

# ======= ğŸŒ Flaskï¼ˆãƒ–ãƒ©ã‚¦ã‚¶å…±æœ‰ï¼‰ =======
app = Flask(__name__)
CORS(app)
browser_data: dict = {}

# ======= ğŸ’¬ ä¼šè©±å±¥æ­´ï¼ˆdeque ã§ä¸Šé™ 30ï¼‰ =======
from collections import deque
messages = deque(maxlen=30)  # {"role": "...", "content": "..."}

# ======= ğŸ ã‚¢ãƒ—ãƒªç¨¼åƒãƒ•ãƒ©ã‚° =======
is_running = True   # ESC ã§ False ã«

# ---------------------------------------------------------------------
# ğŸ§  è¨˜æ†¶ãƒ˜ãƒ«ãƒ‘
# ---------------------------------------------------------------------
def load_persona() -> str:
    """JSON ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨˜æ†¶ã‚’èª­ã¿å–ã‚Šã€ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨æ–‡å­—åˆ—ã«å¤‰æ›"""
    if not MEMORY_FILE.exists():
        return ""
    with open(MEMORY_FILE, encoding="utf-8") as f:
        memory_data = json.load(f)
    memory_lines = [f"{k}ï¼š{v}" for k, v in memory_data.items()]
    return "ã“ã‚Œã¯è¦šãˆã¦ãŠãã¹ããƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã§ã™ã€‚\n" + "\n".join(memory_lines)

def save_persona(new_data: dict):
    """è¨˜æ†¶ JSON ã« key:value ã‚’è¿½åŠ ï¼æ›´æ–°ï¼ˆæ’ä»–åˆ¶å¾¡ä»˜ãï¼‰"""
    with MEMORY_LOCK:
        memory_data = {}
        if MEMORY_FILE.exists():
            with open(MEMORY_FILE, encoding="utf-8") as f:
                memory_data = json.load(f)
        memory_data.update(new_data)
        with open(MEMORY_FILE, "w", encoding="utf-8") as f:
            json.dump(memory_data, f, indent=2, ensure_ascii=False)

def handle_memory_command(user_text: str):
    """ã€è¦šãˆã¦ï½ã€ã€ã“ã‚Œã¯å¿˜ã‚Œã¦ï½ã€ã€ï½ã£ã¦è¦šãˆã¦ã‚‹ï¼Ÿã€ã‚’å‡¦ç†"""
    try:
        if user_text.startswith("è¦šãˆã¦"):
            info = user_text.replace("è¦šãˆã¦", "").strip()
            if "ã¯" in info:
                key, value = info.split("ã¯", 1)
                save_persona({key.strip(): value.strip()})
                return f"ã†ã‚“ã€{key.strip()}ã¯ã€{value.strip()}ã€ã£ã¦è¦šãˆãŸã‚ˆï¼"
            return "ã†ãƒ¼ã‚“ã€ãªã‚“ã¦è¦šãˆã‚Œã°ã„ã„ã‹åˆ†ã‹ã‚“ãªã‹ã£ãŸ..."

        if user_text.startswith("ã“ã‚Œã¯å¿˜ã‚Œã¦"):
            key = user_text.replace("ã“ã‚Œã¯å¿˜ã‚Œã¦", "").strip()
            with MEMORY_LOCK:
                if MEMORY_FILE.exists():
                    with open(MEMORY_FILE, encoding="utf-8") as f:
                        memory_data = json.load(f)
                    if key in memory_data:
                        del memory_data[key]
                        with open(MEMORY_FILE, "w", encoding="utf-8") as f:
                            json.dump(memory_data, f, indent=2, ensure_ascii=False)
                        return f"ã€{key}ã€ã£ã¦è¨˜æ†¶ã¯æ¶ˆã—ãŸã‚ˆ"
            return f"ã€{key}ã€ã£ã¦è¨˜æ†¶ã¯ãªã‹ã£ãŸã¿ãŸã„"

        if user_text.endswith("ã£ã¦è¦šãˆã¦ã‚‹ï¼Ÿ"):
            key = user_text.replace("ã£ã¦è¦šãˆã¦ã‚‹ï¼Ÿ", "").strip()
            if MEMORY_FILE.exists():
                with open(MEMORY_FILE, encoding="utf-8") as f:
                    memory_data = json.load(f)
                if key in memory_data:
                    return f"ã†ã‚“ã€ã€{key}ã€ã¯ã€{memory_data[key]}ã€ã£ã¦è¦šãˆã¦ã‚‹ã‚ˆï¼"
            return f"ã”ã‚ã‚“ã€ã€{key}ã€ã¯è¦šãˆã¦ãªã„ã¿ãŸã„â€¦"
    except Exception as e:
        return f"âš ï¸ è¨˜æ†¶å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}"
    return None

# ---------------------------------------------------------------------
# ğŸ” ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼å¤©æ°—ï¼ãƒ–ãƒ©ã‚¦ã‚¶è¦ç´„
# ---------------------------------------------------------------------
def get_latest_news(limit=5):
    feed_url = "https://news.yahoo.co.jp/rss/topics/top-picks.xml"
    feed = feedparser.parse(feed_url)
    if not feed.entries:
        return "ã”ã‚ã‚“ã­ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã§ããªã‹ã£ãŸã¿ãŸã„ã€‚"
    items = [entry.title for entry in feed.entries[:limit]]
    return "ğŸ“¢ æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã ã‚ˆï¼\n" + "\n".join(f"{i+1}. {t}" for i, t in enumerate(items))

def get_lat_lon(city):
    geo_url = f"http://api.openweathermap.org/geo/1.0/direct"
    params = {"q": city, "limit": 1, "appid": OPENWEATHER_API_KEY}
    try:
        res = requests.get(geo_url, params=params, timeout=10).json()
        if res:
            return res[0]["lat"], res[0]["lon"]
    except Exception as e:
        print("âš ï¸ ç·¯åº¦çµŒåº¦å–å¾—ã‚¨ãƒ©ãƒ¼:", e)
    return None, None

def get_daily_weather_by_day(city="Tokyo", offset=0, lang="ja"):
    lat, lon = get_lat_lon(city)
    if lat is None:
        return "éƒ½å¸‚åã‹ã‚‰ç·¯åº¦çµŒåº¦ãŒå–å¾—ã§ããªã‹ã£ãŸã‚ˆ"
    url = "https://api.openweathermap.org/data/3.0/onecall"
    params = {
        "lat": lat, "lon": lon, "exclude": "current,minutely,hourly,alerts",
        "appid": OPENWEATHER_API_KEY, "units": "metric", "lang": lang
    }
    try:
        daily = requests.get(url, params=params, timeout=10).json().get("daily", [])
        if len(daily) <= offset:
            return "ãã®æ—¥ã®å¤©æ°—ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‚ˆ"
        day = daily[offset]
        dt = time.strftime("%m/%d", time.gmtime(day["dt"]))
        weather = day["weather"][0]["description"]
        Tmin, Tmax = day["temp"]["min"], day["temp"]["max"]
        label = ["ä»Šæ—¥", "æ˜æ—¥", "æ˜å¾Œæ—¥"][offset] if offset < 3 else f"{offset}æ—¥å¾Œ"
        return f"{label}ï¼ˆ{dt}ï¼‰ã®{city}ã®å¤©æ°—ã¯ã€Œ{weather}ã€ã€æœ€ä½{Tmin:.1f}â„ƒã€æœ€é«˜{Tmax:.1f}â„ƒã ã‚ˆâ˜€ï¸"
    except Exception as e:
        return f"âš ï¸ å¤©æ°—å–å¾—ã‚¨ãƒ©ãƒ¼: {e}"

def get_daily_weather(city="Tokyo", lang="ja"):
    lat, lon = get_lat_lon(city)
    if lat is None:
        return "éƒ½å¸‚åã‹ã‚‰ç·¯åº¦çµŒåº¦ãŒå–å¾—ã§ããªã‹ã£ãŸã‚ˆ"
    url = "https://api.openweathermap.org/data/3.0/onecall"
    params = {
        "lat": lat, "lon": lon, "exclude": "current,minutely,hourly,alerts",
        "appid": OPENWEATHER_API_KEY, "units": "metric", "lang": lang
    }
    try:
        daily = requests.get(url, params=params, timeout=10).json().get("daily", [])[:7]
        if not daily:
            return "é€±é–“å¤©æ°—ãŒå–å¾—ã§ããªã‹ã£ãŸã‚ˆ"
        lines = []
        for d in daily:
            dt = time.strftime("%m/%d", time.gmtime(d["dt"]))
            desc = d["weather"][0]["description"]
            Tmin, Tmax = d["temp"]["min"], d["temp"]["max"]
            lines.append(f"{dt}ï¼š{desc}ï¼ˆ{Tmin:.1f}ã€œ{Tmax:.1f}â„ƒï¼‰")
        return "ğŸ“… é€±é–“å¤©æ°—ã ã‚ˆï¼\n" + "\n".join(lines)
    except Exception as e:
        return f"âš ï¸ å¤©æ°—å–å¾—ã‚¨ãƒ©ãƒ¼: {e}"

def handle_search_command(text):
    if "ãƒ‹ãƒ¥ãƒ¼ã‚¹" in text:
        return get_latest_news()
    if "å¤©æ°—" in text:
        if re.search(r"(æ˜å¾Œæ—¥|ã‚ã•ã£ã¦)", text):
            return get_daily_weather_by_day(offset=2)
        if re.search(r"(æ˜æ—¥|ã‚ã—ãŸ)", text):
            return get_daily_weather_by_day(offset=1)
        if re.search(r"(ä»Šæ—¥|ãã‚‡ã†)", text):
            return get_daily_weather_by_day(offset=0)
        return get_daily_weather()
    return None

# ---------------------------------------------------------------------
# ğŸ¤– Gemini å¿œç­”ç”Ÿæˆ
# ---------------------------------------------------------------------
SYSTEM_PROMPT = (
    "ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
    "ãƒ—ãƒ­ã¨ã—ã¦ã®è‡ªè¦šã‚’ã‚‚ã£ã¦ã‚µãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚"
    "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å•ã„ã«çš„ç¢ºã«ç­”ãˆãŸã‚Šã€å›°ã£ã¦ã„ãã†ãªäº‹æŸ„ã«ç©æ¥µçš„ã«æ‰‹åŠ©ã‘ã™ã‚‹ã€‚"
    "èª¬æ˜ã¯ç°¡æ½”ã«çŸ­ãã€‚å£èª¿ã¯å¥³ã®å­ã§ã€æ˜ã‚‹ãçŸ¥çš„ã«ã€‚"
    "æ•¬èªã¯ä½¿ã‚ãšã«ã‚­ãƒŸã¨è©±ã™å£èª¿ã§è¿”ã—ã¦ã­ã€‚"
)

def convert_history(msgs):
    """OpenAI å½¢å¼ â†’ Gemini å½¢å¼ã«å¤‰æ›"""
    return [{"role": m["role"], "parts": [m["content"]]} for m in msgs]


def to_chat_history(msgs):
    """deque â†’ Gemini ç”¨ historyï¼ˆuser / model ã ã‘ï¼‰"""
    chat = []
    for m in msgs:
        role = "user" if m["role"] == "user" else "model"
        chat.append({"role": role, "parts": [m["content"]]})
    return chat

def get_gpt_reply(user_input: str) -> str:
    # ğŸ§  è¨˜æ†¶ã‚’ãƒ­ãƒ¼ãƒ‰
    memory = load_persona()          # ç©ºãªã‚‰ ""

    # â‘  1 æœ¬ç›®ã® user ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤º+è¨˜æ†¶ã‚’è©°ã‚è¾¼ã‚€
    preamble = SYSTEM_PROMPT + ("\n" + memory if memory else "")

    # â‘¡ ç›´è¿‘å±¥æ­´ã‚’ user/model å½¢å¼ã§ç”¨æ„
    chat_history = [{"role": "user", "parts": [preamble]}]
    chat_history += to_chat_history(messages)
    chat_history.append({"role": "user", "parts": [user_input]})

    try:
        response = GEMINI_MODEL.generate_content(chat_history)
        reply = response.text.strip()

        # â‘¢ å±¥æ­´ã‚’æ›´æ–°ï¼ˆdeque ãªã®ã§è‡ªå‹•ã§å¤ã„åˆ†ã¯æ¨ã¦ã‚‹ï¼‰
        messages.append({"role": "user",      "content": user_input})
        messages.append({"role": "assistant", "content": reply})
        return reply

    except Exception as e:
        return f"âš ï¸ Gemini å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}"



# ---------------------------------------------------------------------
# ğŸ™ï¸ éŒ²éŸ³ â†’ Whisper æ–‡å­—èµ·ã“ã—
# ---------------------------------------------------------------------
def smart_record(max_duration=8): # éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
    print("ğŸ¤éŸ³å£°å…¥åŠ›é–‹å§‹")
    buffer, is_recording, silence_start = [], False, None
    stop_requested = False

    def monitor_stop_key():
        nonlocal stop_requested
        while True:
            if keyboard.is_pressed("F2"):
                stop_requested = True
                break
            time.sleep(0.1)
    threading.Thread(target=monitor_stop_key, daemon=True).start()

    def callback(indata, frames, time_info, status):
        nonlocal is_recording, silence_start, buffer
        volume = np.linalg.norm(indata)
        if not is_recording and volume > THRESHOLD_START:
            is_recording = True
            buffer.append(indata.copy())
        elif is_recording:
            buffer.append(indata.copy())
            if volume < THRESHOLD_STOP:
                if silence_start is None:
                    silence_start = time.time()
                elif time.time() - silence_start > SILENCE_DURATION:
                    raise sd.CallbackStop()
            else:
                silence_start = None
        if stop_requested:
            print("ğŸ” éŸ³å£°å…¥åŠ›çµ‚äº†")
            raise sd.CallbackStop()

    with sd.InputStream(callback=callback, samplerate=SAMPLE_RATE, channels=1):
        try:
            sd.sleep(int(max_duration * 1000))
        except sd.CallbackStop:
            pass

    if not buffer:
        return None
    audio_data = np.concatenate(buffer, axis=0)
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    sf.write(tmp.name, audio_data, SAMPLE_RATE)
    return tmp.name

def transcribe_audio(path: str) -> str:
    """Whisper ã§æ–‡å­—èµ·ã“ã—"""
    segments, _ = whisper_model.transcribe(path)
    return " ".join(s.text.strip() for s in segments)

# ---------------------------------------------------------------------
# ğŸ—£ï¸ AIVISpeech éŸ³å£°åˆæˆ â†’ å†ç”Ÿ
# ---------------------------------------------------------------------
def synthesize_voice(text: str, speaker=1325133120, speed=1.2, volume=0.3):
    """AIVISpeech ã‚¨ãƒ³ã‚¸ãƒ³ã§ WAV ã‚’ç”Ÿæˆã—ãƒ‘ã‚¹ã‚’è¿”ã™"""
    try:
        query = requests.post(
            "http://127.0.0.1:10101/audio_query",
            params={"text": text, "speaker": speaker}
        ).json()
        query.update(speedScale=speed, volumeScale=volume)
        audio = requests.post(
            "http://127.0.0.1:10101/synthesis",
            params={"speaker": speaker}, json=query
        )
        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
        tmp.write(audio.content)
        return tmp.name
    except Exception as e:
        print("âš ï¸ éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼:", e)
        return None

def play_voice(path: str):
    """WAV ã‚’å†ç”Ÿï¼ˆF2 ã§ã‚¹ã‚­ãƒƒãƒ—å¯ï¼‰"""
    if not path or not os.path.exists(path):
        print("âš ï¸ å†ç”Ÿãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
        return
    stop_playback = False
    def monitor():
        nonlocal stop_playback
        while is_running:
            if keyboard.is_pressed("F2"):
                stop_playback = True
                break
            time.sleep(0.1)
    threading.Thread(target=monitor, daemon=True).start()
    data, fs = sf.read(path)
    sd.play(data, fs)
    while sd.get_stream().active:
        if stop_playback or not is_running:
            print("ğŸ” å†ç”Ÿä¸­æ­¢")
            sd.stop()
            break
        time.sleep(0.1)
    sd.wait()
    try:
        os.remove(path)
    except Exception:
        pass

# ---------------------------------------------------------------------
# ğŸŒ Flask å—ä¿¡ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# ---------------------------------------------------------------------
@app.route("/browser-data", methods=["POST"])
def browser_data_endpoint():
    global browser_data
    browser_data = request.json or {}
    print("ğŸ“‚ å—ä¿¡ãƒ–ãƒ©ã‚¦ã‚¶ãƒ‡ãƒ¼ã‚¿:", browser_data)
    return "OK", 200

def run_flask_server():
    app.run(port=5000, debug=False, use_reloader=False)

threading.Thread(target=run_flask_server, daemon=True).start()

def handle_browser_command():
    """æœ€æ–°ãƒ–ãƒ©ã‚¦ã‚¶ãƒšãƒ¼ã‚¸ã‚’è¦ç´„ï¼ˆGemini-Flash ä»•æ§˜æº–æ‹ ç‰ˆï¼‰"""
    if not browser_data:
        return "ğŸŒ ãƒ–ãƒ©ã‚¦ã‚¶ã®æƒ…å ±ãŒã¾ã å—ä¿¡ã•ã‚Œã¦ã„ãªã„ã‚ˆã€‚"

    url   = browser_data.get("url")
    title = browser_data.get("title", "ã‚¿ã‚¤ãƒˆãƒ«ãªã—")

    try:
        html  = requests.get(url, timeout=10).text
        soup  = BeautifulSoup(html, "html.parser")
        text  = soup.get_text()[:3000]        # 3000 æ–‡å­—ã«åˆ‡ã‚Šè©°ã‚

        # â”€â”€ Gemini å½¢å¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ â”€â”€
        first_user = (
            "ä»¥ä¸‹ã®ãƒšãƒ¼ã‚¸å†…å®¹ã‚’æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãçŸ­ãè¦ç´„ã—ã€"
            "æ„Ÿæƒ³ã‚’æ¥½ã—ããŠè©±ã—ã¦ã­ã€‚\n"
            "ã‚¿ã‚¤ãƒˆãƒ«: " + title +
            "\nå†…å®¹:\n" + text
        )

        chat = [
            {"role": "user",  "parts": [first_user]}
        ]

        response = GEMINI_MODEL.generate_content(chat)
        summary = response.text.strip()

        # é™¤å»ã—ãŸã„ãƒ•ãƒ¬ãƒ¼ã‚ºã®ãƒªã‚¹ãƒˆ
        phrases_to_remove = [
            "**ç‹¬è‡ªã®è©•ä¾¡ï¼š**",
            "**ç‹¬è‡ªã®è©•ä¾¡ï¼ˆé›‘è«‡å£èª¿ï¼‰ï¼š**",
            "#",
        ]

        for phrase in phrases_to_remove:
            summary = summary.replace(phrase, "")
      
        return summary

    except Exception as e:
        return f"è¦ç´„ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}"



# ---------------------------------------------------------------------
# ğŸ›ï¸ éŸ³å£°å…¥åŠ›â†’å¿œç­” ä¸»å‡¦ç†
# ---------------------------------------------------------------------
def process_audio_and_generate_reply(audio_path):
    user_text = transcribe_audio(audio_path)
    print(f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_text}")

    # â‘  è¨˜æ†¶ç³»
    if mem := handle_memory_command(user_text):
        print("ğŸ§ ", mem)
        return synthesize_voice(mem)

    # â‘¡ æ¤œç´¢ç³»
    if result := handle_search_command(user_text):
        print("ğŸ”", result)
        return synthesize_voice(result)

    # â‘¢ ãƒ–ãƒ©ã‚¦ã‚¶è¦ç´„
    if "ãƒšãƒ¼ã‚¸ã®æƒ…å ±ã‚’æ•™ãˆã¦" in user_text:
        summary = handle_browser_command()
        print("ğŸŒ", summary)
        return synthesize_voice(summary)

    # â‘£ é€šå¸¸å¯¾è©±
    reply = get_gpt_reply(user_text)
    print("ğŸ¤–ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ", reply)
    return synthesize_voice(reply)

# ---------------------------------------------------------------------
# âŒ¨ï¸ ã‚­ãƒ¼ç›£è¦– / ãƒ«ãƒ¼ãƒ—
# ---------------------------------------------------------------------
def monitor_keys():
    global is_running
    while is_running:
        if keyboard.is_pressed("esc"):
            is_running = False
            print("ğŸ‘‹ ESC ã§çµ‚äº†")
        time.sleep(0.1)

def main():
    global is_running
    print("ğŸ” F2 ã§éŒ²éŸ³é–‹å§‹ / çµ‚äº† | ESC ã§ã‚¢ãƒ—ãƒªçµ‚äº†")
    threading.Thread(target=monitor_keys, daemon=True).start()
    recording = False
    while is_running:
        if keyboard.is_pressed("F2"):
            time.sleep(0.2)               # ãƒãƒ£ã‚¿ãƒªãƒ³ã‚°é˜²æ­¢
            if not recording:
                recording = True
                try:
                    audio = smart_record()
                    if not audio:
                        print("âš ï¸ éŒ²éŸ³å¤±æ•—")
                        recording = False
                        continue
                    import concurrent.futures as cf
                    with cf.ThreadPoolExecutor() as ex:
                        voice_path = ex.submit(process_audio_and_generate_reply, audio).result()
                    play_voice(voice_path)
                except Exception as e:
                    print("âš ï¸ ã‚¨ãƒ©ãƒ¼:", e)
                finally:
                    recording = False
        time.sleep(0.1)

if __name__ == "__main__":
    main()
